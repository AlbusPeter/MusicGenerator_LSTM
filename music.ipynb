{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('./data/input.txt','r')\n",
    "data = list(data)\n",
    "data_use = []\n",
    "data_f = []\n",
    "index = 0\n",
    "temp = ''\n",
    "for d in data:\n",
    "    if d == \"<start>\\r\\n\":\n",
    "        index = 1\n",
    "        continue\n",
    "    if d == '<end>\\r\\n':\n",
    "        index = 0\n",
    "    if index == 1:\n",
    "        temp = temp + str(d)\n",
    "    if index == 0:\n",
    "        data_use.append(temp)\n",
    "        temp = ''\n",
    "#print(d)\n",
    "for d in data_use:\n",
    "    if len(d) > 40:\n",
    "        data_f.append(d)\n",
    "data_use = data_f\n",
    "all_character = set()\n",
    "counter = 0\n",
    "for d in data_use:\n",
    "    for dd in d:\n",
    "        all_character.add(dd)\n",
    "all_character = list(all_character)\n",
    "nletter = len(all_character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XIV?me si?cle)\r\n",
      "Z:Transcrit et/ou corrig? par Michel BELLON - 2005-03-27\r\n",
      "Z:Pour toute observation mailto:galouvielle@free.fr\r\n",
      "M:2/2\r\n",
      "L:1/4\r\n",
      "Q:1/4=110\r\n",
      "K:Fmaj\r\n",
      "V:1\r\n",
      "dd/2c/2 dB| GB c2|_e/2d/2B/2c/2 AG|Bc c/2B/2 G|F4|dd/2c/2 dB| GB c2|_e/2d/2B/2c/2 AG|Bc c/2B/2 G/2A/4F/4|G2 zG|\r\n",
      "w:Stel-__la splen-dens in mon-____te ut so-lis ra-_di-um Mi-__ra-cu-lis ser-ra-____to ex-au-di po-_pu-__lum  Prin-\r\n",
      "Gd eg|ef/2d/2 ce|fd c/2B/2B/2A/2|G2 zG|Gd eg|ef/2d/2 ce|fd c/2B/2B/2A/2|G2 z2||\r\n",
      "w:ci-pes et ma-gna-__ tes ex-stir-pe re-_gi-_a sae-cu-li po-tes-ta-__tes ob-ten-ta ve-_ni-_a\r\n",
      "dd/2c/2 dB| GB c2|_e/2d/2B/2c/2 AG|Bc c/2B/2 G|F4|dd/2c/2 dB| GB c2|_e/2d/2B/2c/2 AG|Bc c/2B/2 G/2A/4F/4|G4|]\r\n",
      "w:Pe-__cca mi num pro-cla-____mant tu den tes pec-_to-ra Po-__pli te fle-xo cla-____mant hic A-ve Ma-_ri-__a\r\n",
      "V:2\r\n",
      "G2 GB|dG F2|B2 cd|GF cd|f4| G2 GB|dG F2|B2 cd|GF Bc|d2 zd-|\r\n",
      "d G2 G|cB A2|FG Bc|d2 zd-|d G2 G|cB A2|FG Bc|d2 z2|\r\n",
      "G2 GB|dG F2|B2 cd|GF cd|f4| G2 GB|dG F2|B2 cd|GF Bc|d4|]\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_use[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line),nletter)\n",
    "    position = np.zeros(len(line))\n",
    "    for i, letter in enumerate(line):\n",
    "        position[i] = all_character.index(letter)\n",
    "        tensor[i][all_character.index(letter)] = 1\n",
    "    position = torch.LongTensor(position[1:])\n",
    "    return autograd.Variable(tensor[:-1,:]).cuda(),autograd.Variable(position).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_g(data,batch_size):\n",
    "    lyric = np.random.randint(len(data))\n",
    "    #print(len(data[lyric]))\n",
    "    if len(data[lyric])-batch_size >0:\n",
    "        interval_s = np.random.randint(len(data[lyric])-batch_size)\n",
    "        return data[lyric][interval_s:interval_s+batch_size]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self,letter_dim,hidden_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.letter_dim = letter_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        self.lstm = nn.LSTM(letter_dim,hidden_dim)\n",
    "        self.hidden2out = nn.Linear(hidden_dim,letter_dim)\n",
    "    def init_hidden(self):\n",
    "        return (autograd.Variable(torch.zeros(1, 1, self.hidden_dim)).cuda(),\n",
    "                autograd.Variable(torch.zeros(1, 1, self.hidden_dim)).cuda())\n",
    "    def forward(self,line):\n",
    "        lstm_out, self.hidden = self.lstm(line.view(len(line),1,-1), self.hidden)\n",
    "        out_space = self.hidden2out(lstm_out.view(len(lstm_out),-1))\n",
    "        out_scores = F.softmax(out_space / 1.0,dim = 1)\n",
    "        return out_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 100\n",
    "batch_size = 100\n",
    "lstm = LSTM(nletter,hidden_dim).cuda()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4.5434\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.3015\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.2514\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1084\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0640\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0433\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1144\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.2888\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0564\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0651\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.3035\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0086\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0535\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.2270\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9860\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0017\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1195\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0171\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9694\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0058\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0694\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9905\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9730\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8892\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1191\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9110\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8746\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1632\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1227\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8034\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0969\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1073\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1407\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0110\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1641\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1599\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9147\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9353\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9578\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8855\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0520\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0293\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0172\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9260\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1139\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0911\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0424\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8404\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9249\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8026\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9812\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9698\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0042\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8658\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0134\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0159\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0020\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9350\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9731\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8918\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9376\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9322\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8690\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0346\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9547\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.2053\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0469\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1315\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0982\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0297\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9547\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8475\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9477\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1043\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9914\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.2763\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9178\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0148\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9165\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8725\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8916\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0873\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9243\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.2707\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1607\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9427\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0031\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0275\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0837\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9254\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9109\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1092\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9234\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8649\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8497\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8639\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0309\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.0932\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1886\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 4.1771\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000000):\n",
    "    lstm.zero_grad()\n",
    "    batch = batch_g(data_use,batch_size)\n",
    "#     print(batch)\n",
    "#     print('\\n')\n",
    "    if len(batch)>0:\n",
    "        batch_in,batch_t = lineToTensor(batch)\n",
    "        lstm.hidden = lstm.init_hidden()\n",
    "        out_scores = lstm(batch_in)\n",
    "        loss = loss_function(out_scores,batch_t)\n",
    "        if epoch % 10000 == 0:\n",
    "            print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.99993801e-01   3.47041641e-17   4.93132755e-17   3.68659825e-15\n",
      "   3.06322749e-17   8.04442989e-18   3.88795700e-17   3.20973308e-17\n",
      "   4.11795291e-17   3.63599381e-17   1.22431499e-17   3.43132742e-20\n",
      "   8.23901034e-23   3.28833212e-17   2.95029715e-17   6.20019910e-06\n",
      "   1.47898295e-12   7.24900540e-09   4.96574463e-15   1.15888202e-13\n",
      "   8.52889810e-16   3.56669142e-15   3.39689792e-17   4.13975078e-17\n",
      "   3.05936224e-17   1.07577800e-17   2.34670561e-17   3.56275756e-17\n",
      "   3.33338236e-17   1.33306230e-19   6.14014747e-20   5.85424850e-30\n",
      "   3.14274337e-17   2.93518721e-17   3.64735762e-17   2.84013158e-17\n",
      "   3.18630965e-17   4.43852676e-17   1.14399286e-19   3.21241547e-17\n",
      "   6.77188598e-20   1.68442933e-11   3.22934587e-17   3.06237450e-17\n",
      "   8.51846337e-23   3.20602681e-12   4.02311268e-17   3.29599280e-17\n",
      "   3.47560978e-17   2.45767817e-15   3.27668674e-17   8.23728844e-29\n",
      "   3.07898428e-17   1.18559730e-24   1.45255258e-16   3.27976319e-17\n",
      "   1.52501862e-14   4.32249714e-17   2.87376342e-17   2.03008238e-18\n",
      "   3.74715067e-17   4.20386753e-17   1.03511019e-10   2.92345382e-17\n",
      "   2.41904869e-12   4.40190639e-08   3.06616199e-17   3.10049462e-17\n",
      "   3.72312803e-17   2.99984527e-17   3.62189768e-19   3.81622059e-17\n",
      "   3.50273535e-17   2.76435936e-15   7.37208561e-16   3.05854531e-17\n",
      "   6.31441542e-24   2.64396305e-17   3.66165265e-10   1.89311119e-18\n",
      "   3.87022952e-17   3.10209174e-17   3.25215488e-17   3.24819996e-17\n",
      "   3.49582111e-17   3.26590527e-17   2.05384737e-11   5.16507112e-24\n",
      "   2.66530457e-21   4.86401631e-23   4.03645577e-17   1.20787211e-21\n",
      "   4.12512192e-17   3.45314289e-17]\n"
     ]
    }
   ],
   "source": [
    "print(out_scores.data.cpu().numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "present = torch.zeros(1,nletter)\n",
    "present[0][all_character.index('>')] = 1\n",
    "present = autograd.Variable(present).cuda()\n",
    "lyric = []\n",
    "lyric.append(all_character[int(torch.distributions.Categorical(lstm(present).data.cpu()).sample().numpy())])\n",
    "for num_generation in range(400):\n",
    "    #print(lstm.forward(present).cpu())\n",
    "    next_char_index = int(torch.distributions.Categorical(lstm(present).data.cpu()).sample().numpy())\n",
    "    next_char = all_character[next_char_index]\n",
    "    lyric.append(next_char)\n",
    "    present = torch.zeros(1,nletter)\n",
    "    present[0][all_character.index(next_char)] = 1\n",
    "    present = autograd.Variable(present).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f', 'e', ' ', 'd', 'B', 'A', 'G', '|', '\\r', '\\n', 'A', 'G', 'A', 'B', ' ', 'A', 'G', 'A', 'B', '|', 'G', 'A', 'B', 'd', ' ', 'd', 'B', 'A', 'G', '|', 'A', 'G', 'A', 'B', ' ', 'A', '2', 'G', 'A', '|', 'B', '2', 'A', 'B', ' ', 'A', 'G', 'E', 'G', '|', '\\r', '\\n', 'A', '2', 'A', 'B', ' ', 'A', 'G', 'E', 'G', '|', 'A', 'B', 'A', 'G', ' ', 'A', 'B', 'A', 'G', '|', 'A', 'B', 'A', 'G', ' ', 'A', 'B', 'A', 'G', '|', '\\r', '\\n', 'A', 'G', 'A', 'B', ' ', 'A', 'G', 'A', 'B', '|', 'c', 'A', 'G', 'E', ' ', 'A', 'B', 'd', 'e', '|', '|', '\\r', '\\n', '|', ':', ' ', 'f', 'e', 'd', 'e', ' ', 'd', 'B', 'A', 'G', '|', 'c', 'B', 'A', 'G', ' ', 'A', 'B', 'A', 'G', '|', '\\r', '\\n', 'A', 'G', 'A', 'B', ' ', 'A', 'G', 'A', 'B', '|', 'G', 'A', 'B', 'd', ' ', 'd', 'B', 'd', 'e', '|', 'f', 'd', 'e', 'd', ' ', 'B', 'A', 'G', 'E', '|', '\\r', '\\n', 'G', 'A', 'B', 'd', ' ', 'd', '2', 'B', 'd', '|', 'e', 'd', 'e', 'f', ' ', 'e', 'd', 'B', 'd', '|', 'e', '2', 'f', 'e', ' ', 'd', 'B', 'd', 'e', '|', 'f', 'd', 'd', 'e', ' ', 'f', 'd', 'e', 'd', '|', '\\r', '\\n', 'B', 'A', 'B', 'd', ' ', 'e', 'd', 'B', 'd', '|', 'e', 'd', 'e', 'f', ' ', 'e', 'd', 'B', 'd', '|', 'e', '2', 'f', 'e', ' ', 'd', '2', 'B', 'd', '|', '\\r', '\\n', 'e', '2', 'f', 'e', ' ', 'd', 'e', 'f', 'd', '|', 'e', 'd', 'e', 'f', ' ', 'e', 'd', 'B', 'd', '|', 'e', 'f', 'e', 'd', ' ', 'B', 'A', 'G', 'A', '|', 'B', 'A', 'G', 'E', ' ', 'G', '2', 'E', 'G', '|', '\\r', '\\n', 'A', 'G', 'A', 'B', ' ', 'A', 'G', 'E', 'G', '|', 'A', 'B', 'A', 'G', ' ', 'A', 'G', 'E', 'G', '|', 'A', 'B', 'A', 'G', ' ', 'A', '2', 'G', 'A', '|', '\\r', '\\n', 'B', 'A', 'G', 'B', ' ', 'A', 'G', 'E', 'G', '|', 'A', 'B', 'A', 'G', ' ', 'A', 'G', 'E', 'G', '|', '\\r', '\\n', 'A', 'B', 'A', 'G', ' ', 'A', 'B', 'A', 'G', '|', 'A', 'B', 'A', 'G', ' ', 'A', 'B', 'A', 'G', '|', 'A', 'B', 'A', 'G', ' ', 'A', 'B', 'A', 'G', '|', '\\r', '\\n', 'A', 'G', 'A', 'B', ' ', 'A', 'G', 'A', 'B', '|', 'c', 'A', 'G', 'E', ' ', 'A', 'B', 'd', 'e', '|', 'f', 'd', 'e', 'd', ' ', 'B', 'd', 'e', 'd', '|', 'B', 'A', 'G', 'E', ' ']\n"
     ]
    }
   ],
   "source": [
    "print(str(lyric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fe dBAG|\r\n",
      "AGAB AGAB|GABd dBAG|AGAB A2GA|B2AB AGEG|\r\n",
      "A2AB AGEG|ABAG ABAG|ABAG ABAG|\r\n",
      "AGAB AGAB|cAGE ABde||\r\n",
      "|: fede dBAG|cBAG ABAG|\r\n",
      "AGAB AGAB|GABd dBde|fded BAGE|\r\n",
      "GABd d2Bd|edef edBd|e2fe dBde|fdde fded|\r\n",
      "BABd edBd|edef edBd|e2fe d2Bd|\r\n",
      "e2fe defd|edef edBd|efed BAGA|BAGE G2EG|\r\n",
      "AGAB AGEG|ABAG AGEG|ABAG A2GA|\r\n",
      "BAGB AGEG|ABAG AGEG|\r\n",
      "ABAG ABAG|ABAG ABAG|ABAG ABAG|\r\n",
      "AGAB AGAB|cAGE ABde|fded Bded|BAGE \n"
     ]
    }
   ],
   "source": [
    "Music = \"\"\n",
    "for char in lyric:\n",
    "    Music = Music + char\n",
    "print(Music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
