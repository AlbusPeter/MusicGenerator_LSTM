{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('./data/input.txt','r')\n",
    "data = list(data)\n",
    "data_use = []\n",
    "data_f = []\n",
    "index = 0\n",
    "temp = ''\n",
    "for d in data:\n",
    "    if d == \"<start>\\r\\n\":\n",
    "        index = 1\n",
    "        continue\n",
    "    if d == '<end>\\r\\n':\n",
    "        index = 0\n",
    "    if index == 1:\n",
    "        temp = temp + str(d)\n",
    "    if index == 0:\n",
    "        data_use.append(temp)\n",
    "        temp = ''\n",
    "#print(d)\n",
    "for d in data_use:\n",
    "    if len(d) > 40:\n",
    "        data_f.append(d)\n",
    "data_use = data_f\n",
    "all_character = set()\n",
    "counter = 0\n",
    "for d in data_use:\n",
    "    for dd in d:\n",
    "        all_character.add(dd)\n",
    "all_character = list(all_character)\n",
    "nletter = len(all_character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XIV?me si?cle)\r\n",
      "Z:Transcrit et/ou corrig? par Michel BELLON - 2005-03-27\r\n",
      "Z:Pour toute observation mailto:galouvielle@free.fr\r\n",
      "M:2/2\r\n",
      "L:1/4\r\n",
      "Q:1/4=110\r\n",
      "K:Fmaj\r\n",
      "V:1\r\n",
      "dd/2c/2 dB| GB c2|_e/2d/2B/2c/2 AG|Bc c/2B/2 G|F4|dd/2c/2 dB| GB c2|_e/2d/2B/2c/2 AG|Bc c/2B/2 G/2A/4F/4|G2 zG|\r\n",
      "w:Stel-__la splen-dens in mon-____te ut so-lis ra-_di-um Mi-__ra-cu-lis ser-ra-____to ex-au-di po-_pu-__lum  Prin-\r\n",
      "Gd eg|ef/2d/2 ce|fd c/2B/2B/2A/2|G2 zG|Gd eg|ef/2d/2 ce|fd c/2B/2B/2A/2|G2 z2||\r\n",
      "w:ci-pes et ma-gna-__ tes ex-stir-pe re-_gi-_a sae-cu-li po-tes-ta-__tes ob-ten-ta ve-_ni-_a\r\n",
      "dd/2c/2 dB| GB c2|_e/2d/2B/2c/2 AG|Bc c/2B/2 G|F4|dd/2c/2 dB| GB c2|_e/2d/2B/2c/2 AG|Bc c/2B/2 G/2A/4F/4|G4|]\r\n",
      "w:Pe-__cca mi num pro-cla-____mant tu den tes pec-_to-ra Po-__pli te fle-xo cla-____mant hic A-ve Ma-_ri-__a\r\n",
      "V:2\r\n",
      "G2 GB|dG F2|B2 cd|GF cd|f4| G2 GB|dG F2|B2 cd|GF Bc|d2 zd-|\r\n",
      "d G2 G|cB A2|FG Bc|d2 zd-|d G2 G|cB A2|FG Bc|d2 z2|\r\n",
      "G2 GB|dG F2|B2 cd|GF cd|f4| G2 GB|dG F2|B2 cd|GF Bc|d4|]\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_use[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line),nletter)\n",
    "    position = np.zeros(len(line))\n",
    "    for i, letter in enumerate(line):\n",
    "        position[i] = all_character.index(letter)\n",
    "        tensor[i][all_character.index(letter)] = 1\n",
    "    position = torch.LongTensor(position[1:])\n",
    "    return autograd.Variable(tensor[:-1,:]).cuda(),autograd.Variable(position).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_g(data,batch_size):\n",
    "    lyric = np.random.randint(len(data))\n",
    "    #print(len(data[lyric]))\n",
    "    if len(data[lyric])-batch_size >0:\n",
    "        interval_s = np.random.randint(len(data[lyric])-batch_size)\n",
    "        return data[lyric][interval_s:interval_s+batch_size]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self,letter_dim,hidden_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.letter_dim = letter_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        self.lstm = nn.LSTM(letter_dim,hidden_dim)\n",
    "        self.hidden2out = nn.Linear(hidden_dim,letter_dim)\n",
    "    def init_hidden(self):\n",
    "        return (autograd.Variable(torch.zeros(1, 1, self.hidden_dim)).cuda(),\n",
    "                autograd.Variable(torch.zeros(1, 1, self.hidden_dim)).cuda())\n",
    "    def forward(self,line):\n",
    "        lstm_out, self.hidden = self.lstm(line.view(len(line),1,-1), self.hidden)\n",
    "        out_space = self.hidden2out(lstm_out.view(len(lstm_out),-1))\n",
    "#         out_scores = F.softmax(out_space / 1.0,dim = 1)\n",
    "        return out_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 100\n",
    "batch_size = 30\n",
    "lstm = LSTM(nletter,hidden_dim).cuda()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4.5327\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.3036\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9116\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.8929\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.0180\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.0230\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.3382\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 2.7838\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.9355\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.5177\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    lstm.zero_grad()\n",
    "    batch = batch_g(data_use,batch_size)\n",
    "#     print(batch)\n",
    "#     print('\\n')\n",
    "    if len(batch)>0:\n",
    "        batch_in,batch_t = lineToTensor(batch)\n",
    "        lstm.hidden = lstm.init_hidden()\n",
    "        out_scores = lstm(batch_in)\n",
    "        loss = loss_function(out_scores,batch_t)\n",
    "        if epoch % 100 == 0:\n",
    "            print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.54758021e-01   5.49156778e-03   5.47980051e-03   3.61364661e-03\n",
      "   5.90475556e-03   2.92981439e-03   4.23212186e-04   5.27554948e-04\n",
      "   1.20396484e-02   6.94739749e-04   2.17154948e-03   1.26677728e-03\n",
      "   2.03057961e-03   1.58910079e-05   1.15190365e-03   5.82225733e-02\n",
      "   4.63690422e-03   4.93470393e-03   2.06679595e-03   5.00158733e-03\n",
      "   7.87919620e-04   6.03018813e-02   6.46401255e-04   2.04229844e-03\n",
      "   8.87830829e-05   3.77629809e-02   2.20712088e-02   2.25286488e-03\n",
      "   8.08291021e-04   4.04857984e-03   4.58172448e-02   8.96572717e-04\n",
      "   8.50588491e-04   1.32862269e-03   4.97767527e-04   5.46403520e-04\n",
      "   3.24365072e-04   4.98249717e-02   2.34470144e-02   1.58840325e-03\n",
      "   6.00826740e-03   3.62070277e-03   6.56193413e-04   2.52603586e-05\n",
      "   1.05222156e-02   6.82847342e-03   2.11721035e-05   2.10184444e-05\n",
      "   1.67630706e-03   5.24589047e-02   2.69264029e-03   1.21448627e-02\n",
      "   9.93109960e-03   6.39499128e-02   2.90866923e-02   5.16015047e-04\n",
      "   6.12060772e-04   1.02132454e-03   5.39896137e-04   6.94070943e-04\n",
      "   2.55758711e-03   5.43121062e-03   3.16296145e-02   1.21263089e-03\n",
      "   3.79852788e-03   7.86533114e-03   1.87147409e-03   1.76041434e-03\n",
      "   8.19563493e-03   4.67264508e-05   3.51758488e-02   9.57620039e-04\n",
      "   2.28807167e-03   6.16855826e-03   7.22329132e-03   9.35140648e-04\n",
      "   9.09013965e-04   2.95805838e-03   4.33919579e-02   1.85657423e-02\n",
      "   6.04040571e-04   1.65980926e-03   3.66238819e-04   1.92409338e-04\n",
      "   6.49840367e-05   4.49559593e-04   2.02867035e-02   4.84831855e-02\n",
      "   5.27477497e-03   2.68621650e-03   1.05628780e-04   3.02139856e-03\n",
      "   1.50565722e-03   3.47178939e-05]\n"
     ]
    }
   ],
   "source": [
    "print(F.softmax(out_scores / 1.0,dim = 1).data.cpu().numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "present = torch.zeros(1,nletter)\n",
    "present[0][all_character.index('X')] = 1\n",
    "present = autograd.Variable(present).cuda()\n",
    "lyric = []\n",
    "lyric.append(all_character[int(torch.distributions.Categorical(F.softmax(lstm(present)/1.0,dim = 1).data.cpu()).sample().numpy())])\n",
    "for num_generation in range(400):\n",
    "    #print(lstm.forward(present).cpu())\n",
    "    next_char_index = int(torch.distributions.Categorical(F.softmax(lstm(present)/1.0,dim = 1).data.cpu()).sample().numpy())\n",
    "    next_char = all_character[next_char_index]\n",
    "    lyric.append(next_char)\n",
    "    present = torch.zeros(1,nletter)\n",
    "    present[0][all_character.index(next_char)] = 1\n",
    "    present = autograd.Variable(present).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G', 'c', 'f', ' ', 'A', ' ', 'G', '2', 'B', '2', ' ', '>', '2', 'A', 'f', 'B', 'F', 'd', 'B', ' ', ':', 'P', 'e', 'D', 'E', '/', 'B', 'F', 'e', 'A', 'D', 'h', '|', 'e', 'B', ' ', 'e', ' ', 'E', 'e', 'c', 'G', 'B', '2', 'G', 'A', '|', '|', 'B', 'F', 'c', 'e', 'G', '|', 'A', '2', '|', '2', 'G', 'c', '2', 'A', ' ', 'B', 'c', 'F', 'c', '2', 'c', 'd', 'A', '\"', '3', ' ', 'B', '|', 'e', 'A', 'G', 'h', ' ', 'A', '2', 'c', 'A', '|', ' ', 'c', ' ', '|', ' ', 'E', '4', 'G', '\\n', '4', 'G', '|', 'd', 'c', 'A', 'A', 'c', '|', '2', ' ', 'B', ' ', ' ', 'B', 'd', 'G', 'e', '|', 'A', 'B', 'F', '|', 'e', 'B', 'E', '|', 'E', '=', 'c', 'd', 'B', 'B', '3', '1', 'e', 'B', '/', 'G', 'G', '2', 'd', ' ', 'B', '|', ' ', 'B', 'H', 'G', 'd', '|', ' ', 'G', 'B', 'd', 'A', '|', '|', '|', '|', '|', 'F', 'c', 'B', 'f', 'f', 'd', 'Z', 'F', 'd', 'A', 'c', 'A', 'A', 'G', ' ', 'g', 'B', ',', '|', ' ', 'F', 'e', 'B', 'B', 'f', '|', '\"', ' ', 'A', 'B', '|', '2', 'c', '2', 'c', 'A', '|', 'g', 'B', '\\n', 'd', ' ', 'A', 'G', 'c', '-', 'e', ':', 'c', 'c', 'f', '~', '4', 'A', 'G', 'c', '2', 'B', 'D', ' ', 'A', 'd', 'd', '2', 'A', ' ', \"'\", 'c', ':', 'd', '|', 'A', '|', 'G', '|', '2', '3', '|', 'A', 'A', '3', 'A', 'f', 'c', 'A', 'c', ' ', 'G', 'd', 'f', ' ', 'A', '2', '6', ':', 'F', 'A', ':', '^', 'b', 'd', ':', 'B', 'g', 'E', 'E', 'B', 'A', '/', ' ', 'c', 'G', 'A', '3', ' ', 'A', 'F', '|', 'A', 'a', 'B', 'D', ' ', ' ', 'c', ' ', '/', 'a', 'e', '3', ' ', 'B', 'a', 'F', ' ', ':', 'F', ' ', 'd', 'G', 'g', ' ', 'f', '2', 'g', 'D', 'd', '|', 'c', '|', ' ', 'd', '|', '3', 'A', '|', 'B', ' ', 'A', '|', ' ', 'D', '2', 'c', 'B', '|', 'd', '|', 'e', '~', 'G', '|', 'c', 'F', 'G', '!', '|', 'd', ' ', '2', ' ', 'A', ' ', 'd', 'f', 'A', '2', ' ', 'B', '|', '|', ' ', ' ', 'A', '\\\\', 'F', '~', '|', ' ', 'd', 'o', 'g', 'c', '|', ' ', 'A', ' ', 'e', 'f', '2', 'E', 'B', ' ', '3', 'A', '|', 'c', '2', 'f', ':', 'A', 'A', 'B', 'F', 'G', 'A', 'F', '|', '1', 'f', '2', '|', ':', '|', '2', 'd', 'A', '2', 'F', 'd', 'G', 'G', 'A', ' ', 'a']\n"
     ]
    }
   ],
   "source": [
    "print(str(lyric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gcf A G2B2 >2AfBFdB :PeDE/BFeADh|eB e EecGB2GA||BFceG|A2|2Gc2A BcFc2cdA\"3 B|eAGh A2cA| c | E4G\n",
      "4G|dcAAc|2 B  BdGe|ABF|eBE|E=cdBB31eB/GG2d B| BHGd| GBdA|||||FcBffdZFdAcAAG gB,| FeBBf|\" AB|2c2cA|gB\n",
      "d AGc-e:ccf~4AGc2BD Add2A 'c:d|A|G|23|AA3AfcAc Gdf A26:FA:^bd:BgEEBA/ cGA3 AF|AaBD  c /ae3 BaF :F dGg f2gDd|c| d|3A|B A| D2cB|d|e~G|cFG!|d 2 A dfA2 B||  A\\F~| dogc| A ef2EB 3A|c2f:AABFGAF|1f2|:|2dA2FdGGA a\n"
     ]
    }
   ],
   "source": [
    "Music = \"\"\n",
    "for char in lyric:\n",
    "    Music = Music + char\n",
    "print(Music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
