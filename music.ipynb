{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('./data/input.txt','r')\n",
    "data = list(data)\n",
    "data_use = []\n",
    "data_f = []\n",
    "index = 0\n",
    "temp = ''\n",
    "for d in data:\n",
    "    if d == \"<start>\\r\\n\":\n",
    "        index = 1\n",
    "        continue\n",
    "    if d == '<end>\\r\\n':\n",
    "        index = 0\n",
    "    if index == 1:\n",
    "        temp = temp + str(d)\n",
    "    if index == 0:\n",
    "        data_use.append(temp)\n",
    "        temp = ''\n",
    "#print(d)\n",
    "for d in data_use:\n",
    "    if len(d) > 40:\n",
    "        data_f.append(d)\n",
    "data_use = data_f\n",
    "all_character = set()\n",
    "counter = 0\n",
    "for d in data_use:\n",
    "    for dd in d:\n",
    "        all_character.add(dd)\n",
    "all_character = list(all_character)\n",
    "nletter = len(all_character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XIV?me si?cle)\r\n",
      "Z:Transcrit et/ou corrig? par Michel BELLON - 2005-03-27\r\n",
      "Z:Pour toute observation mailto:galouvielle@free.fr\r\n",
      "M:2/2\r\n",
      "L:1/4\r\n",
      "Q:1/4=110\r\n",
      "K:Fmaj\r\n",
      "V:1\r\n",
      "dd/2c/2 dB| GB c2|_e/2d/2B/2c/2 AG|Bc c/2B/2 G|F4|dd/2c/2 dB| GB c2|_e/2d/2B/2c/2 AG|Bc c/2B/2 G/2A/4F/4|G2 zG|\r\n",
      "w:Stel-__la splen-dens in mon-____te ut so-lis ra-_di-um Mi-__ra-cu-lis ser-ra-____to ex-au-di po-_pu-__lum  Prin-\r\n",
      "Gd eg|ef/2d/2 ce|fd c/2B/2B/2A/2|G2 zG|Gd eg|ef/2d/2 ce|fd c/2B/2B/2A/2|G2 z2||\r\n",
      "w:ci-pes et ma-gna-__ tes ex-stir-pe re-_gi-_a sae-cu-li po-tes-ta-__tes ob-ten-ta ve-_ni-_a\r\n",
      "dd/2c/2 dB| GB c2|_e/2d/2B/2c/2 AG|Bc c/2B/2 G|F4|dd/2c/2 dB| GB c2|_e/2d/2B/2c/2 AG|Bc c/2B/2 G/2A/4F/4|G4|]\r\n",
      "w:Pe-__cca mi num pro-cla-____mant tu den tes pec-_to-ra Po-__pli te fle-xo cla-____mant hic A-ve Ma-_ri-__a\r\n",
      "V:2\r\n",
      "G2 GB|dG F2|B2 cd|GF cd|f4| G2 GB|dG F2|B2 cd|GF Bc|d2 zd-|\r\n",
      "d G2 G|cB A2|FG Bc|d2 zd-|d G2 G|cB A2|FG Bc|d2 z2|\r\n",
      "G2 GB|dG F2|B2 cd|GF cd|f4| G2 GB|dG F2|B2 cd|GF Bc|d4|]\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_use[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line),nletter)\n",
    "    position = np.zeros(len(line))\n",
    "    for i, letter in enumerate(line):\n",
    "        position[i] = all_character.index(letter)\n",
    "        tensor[i][all_character.index(letter)] = 1\n",
    "    position = torch.from_numpy(position[1:]).long()\n",
    "    return autograd.Variable(tensor[:-1,:]).cuda(),autograd.Variable(position).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_g(data,batch_size):\n",
    "    lyric = np.random.randint(len(data))\n",
    "    #print(len(data[lyric]))\n",
    "    if len(data[lyric])-batch_size >0:\n",
    "        interval_s = np.random.randint(len(data[lyric])-batch_size)\n",
    "        return data[lyric][interval_s:interval_s+batch_size]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self,letter_dim,hidden_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.letter_dim = letter_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        self.lstm = nn.LSTM(letter_dim,hidden_dim)\n",
    "        self.hidden2out = nn.Linear(hidden_dim,letter_dim)\n",
    "    def init_hidden(self):\n",
    "        return (autograd.Variable(torch.zeros(1, 1, self.hidden_dim)).cuda(),\n",
    "                autograd.Variable(torch.zeros(1, 1, self.hidden_dim)).cuda())\n",
    "    def forward(self,line):\n",
    "        lstm_out, self.hidden = self.lstm(line.view(len(line),1,-1), self.hidden)\n",
    "        out_space = self.hidden2out(lstm_out.view(len(lstm_out),-1))\n",
    "#         out_scores = F.softmax(out_space / 1.0,dim = 1)\n",
    "        return out_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 100\n",
    "batch_size = 30\n",
    "lstm = LSTM(nletter,hidden_dim).cuda()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4.5470\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 2.9171\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 2.7177\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 3.2790\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 2.6153\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1840d3a92637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    lstm.zero_grad()\n",
    "    batch = batch_g(data_use,batch_size)\n",
    "#     print(batch)\n",
    "#     print('\\n')\n",
    "    if len(batch)>0:\n",
    "        batch_in,batch_t = lineToTensor(batch)\n",
    "        lstm.hidden = lstm.init_hidden()\n",
    "        out_scores = lstm(batch_in)\n",
    "        loss = loss_function(out_scores,batch_t)\n",
    "        if epoch % 1000 == 0:\n",
    "            print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.71104241e-02   1.10607070e-03   1.33918819e-03   3.31502379e-05\n",
      "   1.41654843e-02   2.16764340e-04   1.50187581e-04   5.82695466e-05\n",
      "   2.38036358e-04   5.76608318e-06   2.19230401e-06   2.81575958e-05\n",
      "   3.62753053e-06   1.39874965e-08   5.09926060e-04   3.07068348e-01\n",
      "   7.75646186e-05   2.20940914e-03   4.11001565e-05   4.69862454e-04\n",
      "   1.01717458e-04   5.64067566e-04   4.96421808e-06   5.13616018e-04\n",
      "   3.81924256e-05   2.44627520e-02   2.21263953e-02   1.59723204e-04\n",
      "   6.57657365e-05   1.58825220e-04   5.27087366e-03   1.58715648e-05\n",
      "   5.98427562e-07   1.70586172e-05   6.88771161e-06   4.37294686e-04\n",
      "   2.73574522e-04   1.19618692e-01   2.09524371e-02   1.17771442e-05\n",
      "   8.54894810e-04   3.89511610e-04   3.04890855e-05   5.65584924e-05\n",
      "   2.91107081e-05   1.00196747e-03   2.32100865e-06   1.12615282e-07\n",
      "   6.70639682e-04   2.31218830e-01   1.65626942e-03   3.25664914e-05\n",
      "   1.29153822e-02   3.10283471e-02   1.64982153e-03   6.98874192e-06\n",
      "   1.75418268e-06   5.68510814e-06   1.61083954e-05   1.49400387e-06\n",
      "   3.42089054e-03   1.79081992e-03   8.77012238e-02   5.13139385e-05\n",
      "   7.84792239e-04   2.89947563e-03   1.29647771e-04   1.81317586e-03\n",
      "   5.17773791e-04   2.11651741e-06   1.09007144e-02   1.27064879e-04\n",
      "   9.06067493e-04   9.93095455e-05   1.84679637e-04   2.64562022e-05\n",
      "   1.08498360e-04   2.27606436e-03   1.39355529e-02   3.70646158e-04\n",
      "   7.10924542e-06   9.73217357e-06   1.88778029e-06   4.32514662e-06\n",
      "   1.73213618e-06   1.96899200e-04   1.17171584e-02   3.55493575e-02\n",
      "   1.03652268e-03   1.67225488e-03   9.61173009e-06   3.03716253e-04\n",
      "   1.33375230e-04   1.06539017e-04]\n"
     ]
    }
   ],
   "source": [
    "print(F.softmax(out_scores / 1.0,dim = 1).data.cpu().numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "present = torch.zeros(1,nletter)\n",
    "present[0][all_character.index('X')] = 1\n",
    "present = autograd.Variable(present).cuda()\n",
    "lyric = []\n",
    "lyric.append('X')\n",
    "for num_generation in range(400):\n",
    "    #print(lstm.forward(present).cpu())\n",
    "    next_char_index = int(torch.distributions.Categorical(F.softmax(lstm(present)/1.0,dim = 1).data.cpu()).sample().numpy())\n",
    "    next_char = all_character[next_char_index]\n",
    "    lyric.append(next_char)\n",
    "    present = torch.zeros(1,nletter)\n",
    "    present[0][all_character.index(next_char)] = 1\n",
    "    present = autograd.Variable(present).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', '2', 'G', '2', ' ', 'B', '2', 'G', 'f', '|', 'e', '3', '@', 'd', 'c', 'e', 'd', ' ', '|', ' ', '(', '3', '.', 'g', 'z', 'f', 'g', '.', 'g', '3', ' ', 'd', 'c', 'a', '|', '\\r', '\\n', 'B', 'd', 'B', ' ', 'B', 'A', 'B', ' ', '|', ' ', 'G', '3', ' ', 'd', 'e', 'f', '|', '\\r', '\\n', 'G', 'd', 'c', 'A', '|', '\\r', '\\n', 'E', '2', ' ', 'A', '2', ')', '\\r', '\\n', 'N', '2', ' ', '|', ' ', '.', '7', '0', '1', ':', 'F', '3', ' ', 'C', ' ', 'D', ',', ' ', 'S', 'a', ' ', 'd', 'e', 'l', ' ', 'e', ',', ' ', 'H', 'b', 'i', 'n', '\\r', '\\n', 'R', ':', 's', 'o', 'l', ' ', 'e', 'e', '\\r', '\\n', 'R', ':', 's', 'e', 'e', 'd', 'a', 'n', 'o', ' ', 'b', 'a', 'l', 'e', ' ', 'd', 'o', 'q', 't', 'e', 'r', 'i', 'e', 't', ' ', 'C', 'o', 'r', 'V', 'a', 'g', '?', ':', '\\r', '\\n', 'S', ':', 'C', 'a', 'n', 'd', 'e', 'c', 'd', ':', ' ', '\\\\', 'i', 'd', 't', 'r', 'e', '@', 'b', 's', 'e', 'r', 'v', 'e', '\\r', '\\n', 'R', ':', 'C', 'h', 'a', 'n', ' ', 's', 'h', 'i', 'm', ' ', 't', 'o', 'u', 't', ' ', 'o', 'l', 'i', 'o', 'e', 'k', ' ', 'W', 'i', 'r', 'a', '(', '\\r', '\\n', 'T', ':', 'a', 'a', 'd', 'l', 'w', 'e', '\\r', '\\n', 'P', ':', 'S', 'l', 'i', 'd', ' ', 't', 'o', 'z', ' ', 'W', 'o', 's', 'k', 'a', ':', '\\r', '\\n', 'T', ':', '+', 'i', 'r', 'n', 'e', 'l', 'l', 'i', 'n', ' ', 's', '0', 'm', 'a', 'c', 'e', 's', 'c', ',', ' ', 'P', 'o', 'u', 'r', ' ', 'M', 'i', 'c', 'h', 'e', 'n', 's', ' ', 'B', 'f', ' ', 'a', 'n', 'y', 'e', ' ', 'R', 'o', 'u', 'c', 's', '\\r', '\\n', 'R', ':', 's', 'l', 'i', 'd', 'e', '\\r', '\\n', 'Z', ':', 'i', 'd', ':', 'h', 'n', '-', 's', 'e', 'r', 'e', 'g', '-', ' ', 'a', '-', '7', '7', '\\r', '\\n', 'M', ':', 'C', ':', '\\r', '\\n', 'K', ':', 'G', '\\r', '\\n', 'A', 'B', 'B', 'A', '2', ' ', ':', 'E', 'F', 'E', '|', 'G', 'B', 'B', 'c', 'd', ' ', 'A', 'd', 'c', 'r', 'a', 'm', 'e', 'l', 'd', 'u', 'b', ',', ' ', 'T', 'h', 'e', '\\r', '\\n', 'Z', ':', 'i', 'd', ':', 'h', 'n', '-', 'r', 'e', 'e', 'l', '-', '1', '7', '8', '\\r', '\\n', 'M', ':', 'C', '|', '\\r', '\\n', 'K', ':', 'C', '\\r', '\\n', 'c', '2', 'd', 'B', ' ', 'B', 'c', 'A', '2', '|']\n"
     ]
    }
   ],
   "source": [
    "print(str(lyric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2G2 B2Gf|e3@dced | (3.gzfg.g3 dca|\r\n",
      "BdB BAB | G3 def|\r\n",
      "GdcA|\r\n",
      "E2 A2)\r\n",
      "N2 | .701:F3 C D, Sa del e, Hbin\r\n",
      "R:sol ee\r\n",
      "R:seedano bale doqteriet CorVag?:\r\n",
      "S:Candecd: \\idtre@bserve\r\n",
      "R:Chan shim tout olioek Wira(\r\n",
      "T:aadlwe\r\n",
      "P:Slid toz Woska:\r\n",
      "T:+irnellin s0macesc, Pour Michens Bf anye Roucs\r\n",
      "R:slide\r\n",
      "Z:id:hn-sereg- a-77\r\n",
      "M:C:\r\n",
      "K:G\r\n",
      "ABBA2 :EFE|GBBcd Adcrameldub, The\r\n",
      "Z:id:hn-reel-178\r\n",
      "M:C|\r\n",
      "K:C\r\n",
      "c2dB BcA2|\n"
     ]
    }
   ],
   "source": [
    "Music = \"\"\n",
    "for char in lyric:\n",
    "    Music = Music + char\n",
    "print(Music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
